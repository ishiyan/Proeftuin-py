{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1634194937241,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "k_E0VELS4NP2",
    "outputId": "318fd8a1-541e-4c80-f6c8-53e887737e0b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:50:49.983841Z",
     "start_time": "2022-01-30T06:50:49.847455Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1634194938260,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "Qyy2IpTzbgF0",
    "outputId": "dba31e90-5e76-4abc-d262-c73586c76ebe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeZyx1-fcLXe"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmBFBvfbOj0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:50:55.435698Z",
     "start_time": "2022-01-30T06:50:49.985500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11155,
     "status": "ok",
     "timestamp": 1634194949413,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "dPdpNulr5rdc",
    "outputId": "3d3fdba3-f071-4d90-c3da-9a3ce74627af"
   },
   "outputs": [],
   "source": [
    "!pip install ltp\n",
    "!pip install -q -U watermark\n",
    "!pip install -qq transformers\n",
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:50:55.847348Z",
     "start_time": "2022-01-30T06:50:55.436705Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1642,
     "status": "ok",
     "timestamp": 1634194951035,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "pEHKZt-qRG5x",
    "outputId": "c9b85caa-7c2c-4578-fce2-d41c84ef0dc2"
   },
   "outputs": [],
   "source": [
    "#@title Setup & Config\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from collections import Counter\n",
    "import ast\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 10\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHAlx_DgsuY6"
   },
   "source": [
    "## New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:00.601028Z",
     "start_time": "2022-01-30T06:50:55.848260Z"
    },
    "id": "xRdWcGGBFYTu"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertModel\n",
    "PRE_TRAINED_MODEL_NAME = \"hfl/chinese-roberta-wwm-ext\"\n",
    "# PRE_TRAINED_MODEL_NAME = \"hfl/chinese-roberta-wwm-ext-large\"\n",
    "# PRE_TRAINED_MODEL_NAME = \"hfl/chinese-bert-wwm-ext\"\n",
    "# PRE_TRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
    "# PRE_TRAINED_MODEL_NAME = \"ProsusAI/finbert\"\n",
    "# PRE_TRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME,do_lower_case=True)\n",
    "PRE_TRAINED_MODEL_NAME = '/home/bit/stock/model/pretrained-bert/ROBERT_4_model.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg7yz0zXQujX"
   },
   "source": [
    "## Generating the masks of verb, A0, A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:00.608952Z",
     "start_time": "2022-01-30T06:51:00.602158Z"
    },
    "id": "IWNPdn8fg4gG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def string_to_tuples_list(text):\n",
    "  if text is np.nan or text =='[]':\n",
    "    return []\n",
    "  text = ''.join(text.split('], ['))\n",
    "  tmp = eval(text.strip('[').strip(']'))\n",
    "  if not isinstance(tmp[0],tuple):\n",
    "    return [tmp]\n",
    "  return list(tmp)\n",
    "\n",
    "def mask(df):\n",
    "  df = df.reset_index(drop = True)\n",
    "  df['verb_mask'] = 0\n",
    "  df['A0_mask'] = 0\n",
    "  df['A1_mask'] = 0\n",
    "  df['verb_mask'] = df['verb_mask'].astype('object')\n",
    "  df['A0_mask'] = df['A0_mask'].astype('object')\n",
    "  df['A1_mask'] = df['A1_mask'].astype('object')\n",
    "  for index,row in df.iterrows():\n",
    "\n",
    "    df.at[index,'stock_factors'] = [*map(float,df.loc[index,'stock_factors'])]\n",
    "    AV_num = 0\n",
    "    for k,col in enumerate(['verb','A0','A1']):\n",
    "      masks = []\n",
    "      for j in range(len(row['verbA0A1'])):\n",
    "        mask = np.zeros(299)\n",
    "        idx = []\n",
    "        for v in row['verbA0A1'][j][k]:\n",
    "          \n",
    "          idx = idx + [int(i) for i in range(v[0],v[0]+v[1])]\n",
    "        # idx = np.unique(idx).tolist()\n",
    "        counter = Counter(idx)\n",
    "\n",
    "        mask = [0 if counter[i]== 0 else 1/len(counter) for i in range(0,len(mask))]\n",
    "        mask.insert(0,0)\n",
    "        masks.append(mask)\n",
    "      AV_num = len(masks)\n",
    "      for i in range(10 - len(masks)):\n",
    "        masks.append(np.zeros(300))\n",
    "      while len(masks)>10:\n",
    "        masks.pop()\n",
    "      name = col+'_mask'\n",
    "      df.at[index,name] = np.array(masks)\n",
    "    if AV_num>10:\n",
    "      AV_num=10\n",
    "    df.loc[index,'AV_num'] = int(AV_num)\n",
    "  df.AV_num = df.AV_num.astype('int')\n",
    "  df.stock_factors = df.stock_factors.apply(np.array)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.732903Z",
     "start_time": "2022-01-30T06:51:00.609907Z"
    },
    "id": "c4joMCxJKR5a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/pre/train.csv',sep='\\t')\n",
    "df_val = pd.read_csv('../data/pre/val.csv',sep='\\t')\n",
    "df_test = pd.read_csv('../data/pre/test.csv',sep='\\t')\n",
    "df_ood = pd.read_csv('../data/pre/ood.csv',sep='\\t')\n",
    "\n",
    "\n",
    "df_train = df_train.drop(df_train.loc[df_train.verbA0A1.isna()].index)\n",
    "df_test = df_test.drop(df_test.loc[df_test.verbA0A1.isna()].index)\n",
    "df_val = df_val.drop(df_val.loc[df_val.verbA0A1.isna()].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1.isna()].index)\n",
    "\n",
    "df_train = df_train.drop(df_train.loc[df_train.verbA0A1=='[]'].index)\n",
    "df_test = df_test.drop(df_test.loc[df_test.verbA0A1=='[]'].index)\n",
    "df_val = df_val.drop(df_val.loc[df_val.verbA0A1=='[]'].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1=='[]'].index)\n",
    "\n",
    "\n",
    "for col in ['verb','A0','A1']:\n",
    "  df_train[col] = df_train[col].apply(string_to_tuples_list)\n",
    "  df_val[col] = df_val[col].apply(string_to_tuples_list)\n",
    "  df_test[col] = df_test[col].apply(string_to_tuples_list)\n",
    "  df_ood[col] = df_ood[col].apply(string_to_tuples_list)\n",
    "\n",
    "for col in ['stock_factors','verbA0A1']:\n",
    "# for col in ['verbA0A1']:\n",
    "  df_train[col] = df_train[col].apply(ast.literal_eval)\n",
    "  df_val[col] = df_val[col].apply(ast.literal_eval)\n",
    "  df_test[col] = df_test[col].apply(ast.literal_eval)\n",
    "  df_ood[col] = df_ood[col].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "\n",
    "df_train = mask(df_train)\n",
    "df_test = mask(df_test)\n",
    "df_val = mask(df_val)\n",
    "df_ood = mask(df_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.915903Z",
     "start_time": "2022-01-30T06:51:27.733837Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1634194989992,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "bnCu_pWRk8Ba",
    "outputId": "3a0e2ecd-dced-4ccf-97b2-69b702b82f43"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.918559Z",
     "start_time": "2022-01-30T06:51:27.916766Z"
    },
    "id": "xYTC1elyHlS7"
   },
   "outputs": [],
   "source": [
    "# from ltp import LTP\n",
    "# ltp = LTP()\n",
    "# a = tokenizer.tokenize(df_train.loc[4,'text_a'])\n",
    "# for idx,i in enumerate(df_train.verb_mask[4][2]):\n",
    "#   if i != 0:\n",
    "#     print(a[idx-1])\n",
    "# seg,hidden = ltp.seg([df_train.loc[4,'text_a']])\n",
    "# srl = ltp.srl(hidden)\n",
    "# def list_to_string(a):\n",
    "#   return ''.join(a)\n",
    "# for i,s in enumerate(srl[0]):\n",
    "#   if len(s)!=0:\n",
    "#     print(f'verb: {seg[0][i]} arv: ({[[ar[0], list_to_string([str(seg[0][k]) for k in range(ar[1],ar[2]+1)])] for ar in srl[0][i]]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.928856Z",
     "start_time": "2022-01-30T06:51:27.919234Z"
    },
    "id": "AmtpSQB2PTkC"
   },
   "outputs": [],
   "source": [
    "# df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajOfqpcWRBt9"
   },
   "source": [
    "## Creat Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch_klsfERBI6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.936324Z",
     "start_time": "2022-01-30T06:51:27.929734Z"
    },
    "id": "WaKd7JaTy2gw"
   },
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "class_names = ['negative','neutral', 'positive']\n",
    "class GPReviewDataset(Dataset):\n",
    "\n",
    "  def __init__(self, reviews, targets,verb,A0,A1,AV_num,tokenizer,stock_factors, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.stock_factors = stock_factors\n",
    "    self.verb = verb\n",
    "    self.A0 = A0\n",
    "    self.A1 = A1\n",
    "    self.AV_num = AV_num\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "    stock_factors = self.stock_factors[item]\n",
    "    v = self.verb[item]\n",
    "    a0 = self.A0[item]\n",
    "    a1 = self.A1[item]\n",
    "    av_num = self.AV_num[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long),\n",
    "      'stock_factors':torch.tensor(stock_factors),\n",
    "      'verb': torch.tensor(v),\n",
    "      'A0': torch.tensor(a0),\n",
    "      'A1': torch.tensor(a1),\n",
    "      'AV_num': torch.tensor(av_num)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.941854Z",
     "start_time": "2022-01-30T06:51:27.937253Z"
    },
    "id": "cPZSIigpPtEr"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.text_a.to_numpy(),\n",
    "    targets=df.label.to_numpy(),\n",
    "    stock_factors = df.stock_factors,\n",
    "    verb = df.verb_mask,\n",
    "    A0 = df.A0_mask,\n",
    "    A1 = df.A1_mask,\n",
    "    AV_num = df.AV_num,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    # num_workers=4,\n",
    "    shuffle=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.949099Z",
     "start_time": "2022-01-30T06:51:27.942592Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:27.961914Z",
     "start_time": "2022-01-30T06:51:27.949789Z"
    },
    "id": "4bMEUzcABFvn"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, max_len, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, max_len, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, max_len, BATCH_SIZE)\n",
    "ood_data_loader = create_data_loader(df_ood, tokenizer, max_len, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:28.001919Z",
     "start_time": "2022-01-30T06:51:27.963643Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1634194989997,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "vDjd-DrAUt-d",
    "outputId": "674d43cf-a7d6-4e5d-ebc2-bc8f72108a25"
   },
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:28.577195Z",
     "start_time": "2022-01-30T06:51:28.002611Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1702,
     "status": "ok",
     "timestamp": 1634194991680,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "bidtjT6UEKkk",
    "outputId": "36398da4-f9b6-495d-c293-1935f7f71eea"
   },
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:28.599786Z",
     "start_time": "2022-01-30T06:51:28.578173Z"
    },
    "id": "hsRtLnPlWulS"
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.encoder_layer =  nn.TransformerEncoderLayer(d_model=2304, nhead=1)\n",
    "    self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "    self.drop = nn.Dropout(p=0.1)\n",
    "    self.out1 = nn.Linear((self.bert.config.hidden_size*3)*10, (self.bert.config.hidden_size*3)*3)\n",
    "    self.out = nn.Linear((self.bert.config.hidden_size*3)*3, n_classes)\n",
    "    self.avgpool = nn.AvgPool2d((3,2), stride=2)\n",
    "    self.flatten2 = nn.Flatten(2,-1)\n",
    "    self.flatten = nn.Flatten(1,-1)\n",
    "    self.sig = nn.Sigmoid()\n",
    "    self.relu = nn.ReLU()\n",
    "    self.Querry = nn.Linear(self.bert.config.hidden_size*2,self.bert.config.hidden_size*2)\n",
    "    self.Key = nn.Linear(self.bert.config.hidden_size*2,self.bert.config.hidden_size*2)\n",
    "    # self.Self_supervised = nn.Linear(self.bert.config.hidden_size,self.bert.config.hidden_size)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask,verb,A0,A1,AV_num):\n",
    "    #get bert embedding \n",
    "    hidden_state = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )[0]\n",
    "    batch = hidden_state.shape[0]\n",
    "    verb_tmp = verb.clone()\n",
    "    A1_tmp = A1.clone()\n",
    "    #mask verb\n",
    "    AV_idx = []\n",
    "    for idx,num in enumerate(AV_num):\n",
    "      self_label = torch.randint(0,num,(1,))[0]\n",
    "      AV_idx.append(self_label)\n",
    "      verb_tmp[idx,self_label,:]=0\n",
    "      A1_tmp[idx,self_label,:]=0\n",
    "\n",
    "    #verb label\n",
    "    AV_idx = torch.tensor(AV_idx).to(device)\n",
    "\n",
    "    # get K(8*10*1536)\n",
    "    V_mask = torch.unsqueeze(verb,3)\n",
    "    V_mask = torch.cat(768 * [V_mask],3)\n",
    "    V_mask = torch.mean(V_mask*torch.unsqueeze(hidden_state,1),2,True)\n",
    "    \n",
    "    A1_mask = torch.unsqueeze(A1,3)\n",
    "    A1_mask = torch.cat(768 * [A1_mask],3)\n",
    "    A1_mask = torch.mean(A1_mask*torch.unsqueeze(hidden_state,1),2,True)\n",
    "    K = self.Key(torch.squeeze(torch.cat([V_mask,A1_mask],3)).float())\n",
    "    \n",
    "    # get verb embedding after masking(8*10*1*768)\n",
    "    V_mask_mask = torch.unsqueeze(verb_tmp,3)\n",
    "    V_mask_mask = torch.cat(768 * [V_mask_mask],3)\n",
    "    V_mask_mask = torch.mean(V_mask_mask*torch.unsqueeze(hidden_state,1),2,True)\n",
    "    transformer_input = V_mask_mask\n",
    "\n",
    "    #get A0 embedding(8*10*2*768)\n",
    "    A0_mask = torch.unsqueeze(A0,3)\n",
    "    A0_mask = torch.cat(768 * [A0_mask],3)\n",
    "    A0_mask = torch.mean(A0_mask*torch.unsqueeze(hidden_state,1),2,True)\n",
    "    transformer_input = torch.cat([transformer_input,A0_mask],2)\n",
    "\n",
    "    #get A1 embedding(8*10*3*768)\n",
    "    A1_mask_mask = torch.unsqueeze(A1_tmp,3)\n",
    "    A1_mask_mask = torch.cat(768 * [A1_mask_mask],3)\n",
    "    A1_mask_mask = torch.mean(A1_mask_mask*torch.unsqueeze(hidden_state,1),2,True)\n",
    "    transformer_input = torch.cat([transformer_input,A1_mask_mask],2)\n",
    "\n",
    "    #get transformer input(8*10*2304)\n",
    "    transformer_input = self.flatten2(transformer_input.float())\n",
    "\n",
    "    #turn to (10*8*2304)\n",
    "    transformer_input = torch.stack([transformer_input[:,i,:] for i in range(0,len(A0[0]))])\n",
    "\n",
    "    #get transformer output(10*8*2304)\n",
    "    transformer_output = self.transformer_encoder(transformer_input)\n",
    "\n",
    "    #turn to (8*10*2304)\n",
    "    transformer_output = torch.stack([torch.squeeze(transformer_output[:,i,:]) for i in range(0,batch)])\n",
    "    transformer_output = torch.squeeze(transformer_output)\n",
    "\n",
    "    #turn to (8*10*2304)\n",
    "    self_pred = torch.zeros((batch,10))\n",
    "    if transformer_output.dim()==2:\n",
    "      transformer_output = torch.unsqueeze(transformer_output,0)\n",
    "\n",
    "    #Q For CL\n",
    "    for idx,i in enumerate(AV_idx):\n",
    "      Q = torch.unsqueeze(self.Querry(transformer_output[idx,i,list(range(768))+list(range(1536,2304))]),0)\n",
    "      self_pred[idx]=(Q @ K[idx].T)\n",
    "\n",
    "    #get transformer input for classification(8*10*3*768)\n",
    "    transformer_input = torch.cat([V_mask,A0_mask,A1_mask],2)\n",
    "    #get transformer input(8*10*2304)\n",
    "    transformer_input = self.flatten2(transformer_input.float())\n",
    "\n",
    "    #get transformer output(10*8*2304)\n",
    "    transformer_input = torch.stack([transformer_input[:,i,:] for i in range(0,len(A0[0]))])\n",
    "    transformer_output = self.transformer_encoder(transformer_input)\n",
    "\n",
    "    #turn to (8*10*2304)\n",
    "    transformer_output = torch.stack([torch.squeeze(transformer_output[:,i,:]) for i in range(0,batch)])\n",
    "    transformer_output = torch.squeeze(transformer_output)\n",
    "\n",
    "    # handle exception\n",
    "    if transformer_output.dim()==2:\n",
    "      transformer_output = torch.unsqueeze(transformer_output,0)\n",
    "\n",
    "    output = self.flatten(transformer_output.float())\n",
    "    output = self.sig(output)\n",
    "#     output = self.drop(output)\n",
    "    output = self.out1(output)\n",
    "    output = self.sig(output)\n",
    "    output = self.drop(output)\n",
    "    output = self.out(output)\n",
    "\n",
    "    return output,self_pred,AV_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.641539Z",
     "start_time": "2022-01-30T06:51:28.600477Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5657,
     "status": "ok",
     "timestamp": 1634194997335,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "KQEOV2pfYBPs",
    "outputId": "215b9b5c-7356-4e61-e001-61f5dbb29660"
   },
   "outputs": [],
   "source": [
    "model = SentimentClassifier(3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfJO5a0NGPf_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.644178Z",
     "start_time": "2022-01-30T06:51:34.642377Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1634194997338,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "uLl-umJKYGtB",
    "outputId": "30fb9ea3-81b2-4371-a0c7-198c44fe1759"
   },
   "outputs": [],
   "source": [
    "# input_ids = data['input_ids'].to(device)\n",
    "# attention_mask = data['attention_mask'].to(device)\n",
    "# verbs = data['verb'].to(device)\n",
    "# A0s = data['A0'].to(device)\n",
    "# A1s = data['A1'].to(device)\n",
    "# AV_num = data['AV_num'].to(device)\n",
    "# print(input_ids.shape) # batch size x seq length\n",
    "# print(attention_mask.shape) # batch size x seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.654032Z",
     "start_time": "2022-01-30T06:51:34.645168Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1634194997338,
     "user": {
      "displayName": "Nero C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjQRoCAV4q10k-DC7od7DeLQhSUCkvaI26E0x4r=s64",
      "userId": "13659571702895310340"
     },
     "user_tz": -630
    },
    "id": "VX0A_axjYJfP",
    "outputId": "599623bc-5aec-47ba-b3fd-ba2396412792"
   },
   "outputs": [],
   "source": [
    "# F.softmax(model(input_ids, attention_mask,verb = verbs,A0 = A0s,A1 =A1s,AV_num = AV_num)[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82irQeXrOfWI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.666414Z",
     "start_time": "2022-01-30T06:51:34.654684Z"
    },
    "id": "4q2fUr9TYMxW"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYA1f6t3f2ex"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.677307Z",
     "start_time": "2022-01-30T06:51:34.667629Z"
    },
    "id": "oLLFWDvDYeeS"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  correct_predictions_verbs = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    verb = d[\"verb\"].to(device)\n",
    "    A0 = d[\"A0\"].to(device)\n",
    "    A1 = d[\"A1\"].to(device)\n",
    "    AV_num = d[\"AV_num\"].to(device)\n",
    "\n",
    "    outputs,self_outputs,self_labels = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      verb = verb,\n",
    "      A0 = A0,\n",
    "      A1 = A1,\n",
    "      AV_num = AV_num\n",
    "    )\n",
    "    self_outputs = self_outputs.to(device)\n",
    "    self_labels = self_labels.to(device)\n",
    "\n",
    "    if outputs.dim()==1:\n",
    "      outputs = torch.unsqueeze(outputs,0)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    _, self_preds = torch.max(self_outputs, dim=1)\n",
    "    \n",
    "    # print(targets.shape,outputs.shape)\n",
    "    loss = 0.8*loss_fn(outputs, targets)+0.2*loss_fn(self_outputs,self_labels)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    correct_predictions_verbs += torch.sum(self_preds == self_labels)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses),correct_predictions_verbs.double()/n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.691096Z",
     "start_time": "2022-01-30T06:51:34.677947Z"
    },
    "id": "VmDYxiXDYl-u"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      verb = d[\"verb\"].to(device)\n",
    "      A0 = d[\"A0\"].to(device)\n",
    "      A1 = d[\"A1\"].to(device)\n",
    "      AV_num = d[\"AV_num\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        verb = verb,\n",
    "        A0 = A0,\n",
    "        A1 = A1,\n",
    "        AV_num = AV_num\n",
    "      )[0]\n",
    "      \n",
    "      if outputs.dim()==1:\n",
    "        outputs = torch.unsqueeze(outputs,0)\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      \n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:34.704162Z",
     "start_time": "2022-01-30T06:51:34.691943Z"
    },
    "id": "Nkvo-2p93Dnr"
   },
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "# EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZvKK2TkYojZ",
    "outputId": "c2ab0a75-6fee-4af7-8a3e-0846f2c720db",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss, cl_acc = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc} cl_accuracy{cl_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'Pretrained_RoBert_SRL(FC)_CL(VA1).bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:42.636932Z",
     "start_time": "2022-01-30T06:51:42.634471Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "FIyLcNepYr4f",
    "outputId": "3d88c984-833b-4551-c4cb-91d5ea5cb766"
   },
   "outputs": [],
   "source": [
    "len(history[\"train_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:42.782696Z",
     "start_time": "2022-01-30T06:51:42.637557Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "xu7Y2BPzLZgi",
    "outputId": "464a72dd-decd-4758-c2a4-ed850769df71"
   },
   "outputs": [],
   "source": [
    "plt.plot([i.cpu() for i in history['train_acc']], label='train accuracy')\n",
    "plt.plot([i.cpu() for i in history['val_acc']], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:45.669491Z",
     "start_time": "2022-01-30T06:51:42.783510Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "YYMhWiIrBrV4",
    "outputId": "715ceb5a-ae70-4412-a3ab-720a04955b93"
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\n",
    "\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model.load_state_dict(torch.load('Pretrained_RoBert_SRL(FC)_CL(VA1).bin'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:51:45.672856Z",
     "start_time": "2022-01-30T06:51:45.670299Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "KYRPY0C-fFQh",
    "outputId": "5ff644a7-ed8f-4e1d-c846-e26640849d2f"
   },
   "outputs": [],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:52:11.131003Z",
     "start_time": "2022-01-30T06:51:45.673521Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "c7Cckbz8GbDK",
    "outputId": "a3332b1f-6762-40f0-812b-db4844ec2d4d"
   },
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:52:11.136227Z",
     "start_time": "2022-01-30T06:52:11.131737Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "a0Qemnl0FiEb"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      verb = d[\"verb\"].to(device)\n",
    "      A0 = d[\"A0\"].to(device)\n",
    "      A1 = d[\"A1\"].to(device)\n",
    "      AV_num = d['AV_num'].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        verb = verb,\n",
    "        A0 = A0,\n",
    "        A1 = A1,\n",
    "        AV_num = AV_num\n",
    "      )[0]\n",
    "#       _, preds = torch.max(outputs, dim=1)\n",
    "      \n",
    "      if outputs.dim()==1:\n",
    "        outputs = torch.unsqueeze(outputs,0)\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:52:11.150522Z",
     "start_time": "2022-01-30T06:52:11.136977Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True sentiment')\n",
    "  plt.xlabel('Predicted sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:52:31.055189Z",
     "start_time": "2022-01-30T06:52:11.151480Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "YkPHXF0MGiCh",
    "outputId": "648048e5-a674-4137-9efe-105cfea84b32"
   },
   "outputs": [],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=class_names,digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:54:18.699846Z",
     "start_time": "2022-01-30T06:52:31.055921Z"
    }
   },
   "outputs": [],
   "source": [
    "y_ood_review_texts, y_ood_pred, y_ood_pred_probs, y_ood = get_predictions(\n",
    "  model,\n",
    "  ood_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_ood, y_ood_pred, target_names=class_names,digits=4))\n",
    "\n",
    "ood_cm = confusion_matrix(y_ood, y_ood_pred)\n",
    "df_ood_cm = pd.DataFrame(ood_cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_ood_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:56:00.197618Z",
     "start_time": "2022-01-30T06:54:18.700803Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ood = pd.read_csv('../data/pre/ood.csv',sep='\\t')\n",
    "df_ood = df_ood.loc[(df_ood.DATE>='2021-01-01')&(df_ood.DATE<='2021-03-31')]\n",
    "df_ood = df_ood.sort_values(by='DATE')\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "# df_ood = df_ood.loc[:4000]\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1.isna()].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1=='[]'].index)\n",
    "for col in ['verb','A0','A1']:\n",
    "  df_ood[col] = df_ood[col].apply(string_to_tuples_list)\n",
    "\n",
    "for col in ['stock_factors','verbA0A1']:\n",
    "  df_ood[col] = df_ood[col].apply(ast.literal_eval)\n",
    "df_ood = mask(df_ood)\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "ood_data_loader = create_data_loader(df_ood, tokenizer, max_len, BATCH_SIZE)\n",
    "\n",
    "y_ood_review_texts, y_ood_pred, y_ood_pred_probs, y_ood = get_predictions(\n",
    "  model,\n",
    "  ood_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_ood, y_ood_pred, target_names=class_names,digits=4))\n",
    "\n",
    "ood_cm = confusion_matrix(y_ood, y_ood_pred)\n",
    "df_ood_cm = pd.DataFrame(ood_cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_ood_cm)\n",
    "plt.show()\n",
    "\n",
    "df_ood = pd.read_csv('../data/pre/ood.csv',sep='\\t')\n",
    "df_ood = df_ood.loc[(df_ood.DATE>='2021-04-01')&(df_ood.DATE<='2021-06-31')]\n",
    "df_ood = df_ood.sort_values(by='DATE')\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "# df_ood = df_ood.loc[:4000]\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1.isna()].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1=='[]'].index)\n",
    "for col in ['verb','A0','A1']:\n",
    "  df_ood[col] = df_ood[col].apply(string_to_tuples_list)\n",
    "\n",
    "for col in ['stock_factors','verbA0A1']:\n",
    "  df_ood[col] = df_ood[col].apply(ast.literal_eval)\n",
    "df_ood = mask(df_ood)\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "ood_data_loader = create_data_loader(df_ood, tokenizer, max_len, BATCH_SIZE)\n",
    "\n",
    "y_ood_review_texts, y_ood_pred, y_ood_pred_probs, y_ood = get_predictions(\n",
    "  model,\n",
    "  ood_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_ood, y_ood_pred, target_names=class_names,digits=4))\n",
    "\n",
    "ood_cm = confusion_matrix(y_ood, y_ood_pred)\n",
    "df_ood_cm = pd.DataFrame(ood_cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_ood_cm)\n",
    "plt.show()\n",
    "\n",
    "df_ood = pd.read_csv('../data/pre/ood.csv',sep='\\t')\n",
    "df_ood = df_ood.loc[(df_ood.DATE>='2021-07-01')&(df_ood.DATE<='2021-09-31')]\n",
    "df_ood = df_ood.sort_values(by='DATE')\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "# df_ood = df_ood.loc[:4000]\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1.isna()].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1=='[]'].index)\n",
    "for col in ['verb','A0','A1']:\n",
    "  df_ood[col] = df_ood[col].apply(string_to_tuples_list)\n",
    "\n",
    "for col in ['stock_factors','verbA0A1']:\n",
    "  df_ood[col] = df_ood[col].apply(ast.literal_eval)\n",
    "df_ood = mask(df_ood)\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "ood_data_loader = create_data_loader(df_ood, tokenizer, max_len, BATCH_SIZE)\n",
    "\n",
    "y_ood_review_texts, y_ood_pred, y_ood_pred_probs, y_ood = get_predictions(\n",
    "  model,\n",
    "  ood_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_ood, y_ood_pred, target_names=class_names,digits=4))\n",
    "\n",
    "ood_cm = confusion_matrix(y_ood, y_ood_pred)\n",
    "df_ood_cm = pd.DataFrame(ood_cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_ood_cm)\n",
    "plt.show()\n",
    "\n",
    "df_ood = pd.read_csv('../data/pre/ood.csv',sep='\\t')\n",
    "df_ood = df_ood.loc[df_ood.DATE>='2021-10-01']\n",
    "df_ood = df_ood.sort_values(by='DATE')\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "# df_ood = df_ood.loc[:4000]\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1.isna()].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1=='[]'].index)\n",
    "for col in ['verb','A0','A1']:\n",
    "  df_ood[col] = df_ood[col].apply(string_to_tuples_list)\n",
    "\n",
    "for col in ['stock_factors','verbA0A1']:\n",
    "  df_ood[col] = df_ood[col].apply(ast.literal_eval)\n",
    "df_ood = mask(df_ood)\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "ood_data_loader = create_data_loader(df_ood, tokenizer, max_len, BATCH_SIZE)\n",
    "\n",
    "y_ood_review_texts, y_ood_pred, y_ood_pred_probs, y_ood = get_predictions(\n",
    "  model,\n",
    "  ood_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_ood, y_ood_pred, target_names=class_names,digits=4))\n",
    "\n",
    "ood_cm = confusion_matrix(y_ood, y_ood_pred)\n",
    "df_ood_cm = pd.DataFrame(ood_cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_ood_cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:56.010693Z",
     "start_time": "2022-01-30T06:56:00.198509Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ood = pd.read_csv('../data/df_all_year_srl.csv',sep='\\t')\n",
    "# df_ood = df_ood.loc[(df_ood.DATE>='2021-05-05')&(df_ood.DATE<='2021-09-01')]\n",
    "df_ood = df_ood.sort_values(by='DATE')\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "# df_ood = df_ood.loc[:2000]\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1.isna()].index)\n",
    "df_ood = df_ood.drop(df_ood.loc[df_ood.verbA0A1=='[]'].index)\n",
    "for col in ['verb','A0','A1']:\n",
    "  df_ood[col] = df_ood[col].apply(string_to_tuples_list)\n",
    "\n",
    "for col in ['stock_factors','verbA0A1']:\n",
    "  df_ood[col] = df_ood[col].apply(ast.literal_eval)\n",
    "df_ood = mask(df_ood)\n",
    "df_ood = df_ood.reset_index(drop=True)\n",
    "ood_data_loader = create_data_loader(df_ood, tokenizer, max_len, BATCH_SIZE)\n",
    "\n",
    "y_ood_review_texts, y_ood_pred, y_ood_pred_probs, y_ood = get_predictions(\n",
    "  model,\n",
    "  ood_data_loader\n",
    ")\n",
    "\n",
    "print(classification_report(y_ood, y_ood_pred, target_names=class_names,digits=4))\n",
    "\n",
    "ood_cm = confusion_matrix(y_ood, y_ood_pred)\n",
    "df_ood_cm = pd.DataFrame(ood_cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_ood_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.407971Z",
     "start_time": "2022-01-30T06:57:56.011628Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([y_ood_review_texts, y_ood_pred.numpy(), y_ood_pred_probs.numpy(), y_ood.numpy()]).T\n",
    "df = df.rename(columns={0:'text',1:'prediction',2:'probability',3:'labels'})\n",
    "df.to_csv('Pretrained_RoBert_SRL(FC)_CL(VA1)_ood.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.410547Z",
     "start_time": "2022-01-30T06:57:57.408882Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "6QZ0EgQoalz2"
   },
   "outputs": [],
   "source": [
    "# !pip install lit-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.416249Z",
     "start_time": "2022-01-30T06:57:57.411265Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "eAeHdVF7c-QF"
   },
   "outputs": [],
   "source": [
    "# from lit_nlp.api.dataset import Dataset\n",
    "# class MultiNLIData(Dataset):\n",
    "#   \"\"\"Loader for MultiNLI development set.\"\"\"\n",
    "#   def __init__(self, df):\n",
    "#     # Read the eval set from a .tsv file as distributed with the GLUE benchmark.\n",
    "#     # df = pandas.read_csv(path, sep='\\t')\n",
    "#     # Store as a list of dicts, conforming to self.spec()\n",
    "#     self.LABELS = [0,1]\n",
    "#     self._examples = [{\n",
    "#       'sentence': row['DESCRIPTION_EN'],\n",
    "#       # 'hypothesis': row['sentence2'],\n",
    "#       'label': row['LABEL']\n",
    "#       # 'genre': row['genre'],\n",
    "#     } for _, row in df.iterrows()]\n",
    "#   def spec(self):\n",
    "#     return {\n",
    "#       'sentence': lit_types.TextSegment(),\n",
    "#       # 'hypothesis': lit_types.TextSegment(),\n",
    "#       'label': lit_types.CategoryLabel(vocab=self.LABELS),\n",
    "#       # We can include additional fields, which don't have to be used by the model.\n",
    "#       # 'genre': lit_types.Label(),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l5886G4mdXia"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mrSBCdqO0sUs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "f-nX4zrOdxpo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ARdnz5td18VV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iMviJZsfdifG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8h5I2QKodj8b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0-abzg6avOQq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "flJ1xtWNvYej"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.425271Z",
     "start_time": "2022-01-30T06:57:57.417143Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "nBxb2zhWvfaK"
   },
   "outputs": [],
   "source": [
    "# from absl import app\n",
    "# from absl import flags\n",
    "# from absl import logging\n",
    "\n",
    "# from lit_nlp import dev_server\n",
    "# from lit_nlp import server_flags\n",
    "# from lit_nlp.api import model as lit_model\n",
    "# from lit_nlp.api import types as lit_types\n",
    "# # Use the regular GLUE data loaders, because these are very simple already.\n",
    "# from lit_nlp.examples.datasets import glue\n",
    "# from lit_nlp.lib import utils\n",
    "\n",
    "# import torch\n",
    "# import transformers\n",
    "\n",
    "# # NOTE: additional flags defined in server_flags.py\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     \"model_path\",\n",
    "#     \"https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\",\n",
    "#     \"Path to trained model, in standard transformers format, e.g. as \"\n",
    "#     \"saved by model.save_pretrained() and tokenizer.save_pretrained()\")\n",
    "\n",
    "\n",
    "# def _from_pretrained(cls, *args, **kw):\n",
    "#   \"\"\"Load a transformers model in PyTorch, with fallback to TF2/Keras weights.\"\"\"\n",
    "#   try:\n",
    "#     return cls.from_pretrained(*args, **kw)\n",
    "#   except OSError as e:\n",
    "#     logging.warning(\"Caught OSError loading model: %s\", e)\n",
    "#     logging.warning(\n",
    "#         \"Re-trying to convert from TensorFlow checkpoint (from_tf=True)\")\n",
    "#     return cls.from_pretrained(*args, from_tf=True, **kw)\n",
    "\n",
    "\n",
    "# class SimpleSentimentModel(lit_model.Model):\n",
    "#   \"\"\"Simple sentiment analysis model.\"\"\"\n",
    "\n",
    "#   LABELS = [0,1]  # negative, positive\n",
    "\n",
    "#   def __init__(self, model_name_or_path):\n",
    "#     self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "#         model_name_or_path)\n",
    "#     model_config = transformers.AutoConfig.from_pretrained(\n",
    "#         model_name_or_path,\n",
    "#         num_labels=2,\n",
    "#         output_hidden_states=True,\n",
    "#         output_attentions=True,\n",
    "#     )\n",
    "#     # This is a just a regular PyTorch model.\n",
    "#     self.model = _from_pretrained(\n",
    "#         transformers.AutoModelForSequenceClassification,\n",
    "#         model_name_or_path,\n",
    "#         config=model_config)\n",
    "#     self.model.eval()\n",
    "\n",
    "#   ##\n",
    "#   # LIT API implementation\n",
    "#   def max_minibatch_size(self):\n",
    "#     # This tells lit_model.Model.predict() how to batch inputs to\n",
    "#     # predict_minibatch().\n",
    "#     # Alternately, you can just override predict() and handle batching yourself.\n",
    "#     return 16\n",
    "\n",
    "#   def predict_minibatch(self, inputs):\n",
    "#     # Preprocess to ids and masks, and make the input batch.\n",
    "#     encoded_input = self.tokenizer.batch_encode_plus(\n",
    "#         [ex[\"sentence\"] for ex in inputs],\n",
    "#         return_tensors=\"pt\",\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=200,\n",
    "#         padding=\"longest\",\n",
    "#         truncation=\"longest_first\")\n",
    "\n",
    "#     # Check and send to cuda (GPU) if available\n",
    "#     if torch.cuda.is_available():\n",
    "#       self.model.cuda()\n",
    "#       for tensor in encoded_input:\n",
    "#         encoded_input[tensor] = encoded_input[tensor].cuda()\n",
    "#     # Run a forward pass.\n",
    "#     with torch.no_grad():  # remove this if you need gradients.\n",
    "#       out: transformers.modeling_outputs.SequenceClassifierOutput = \\\n",
    "#           self.model(**encoded_input)\n",
    "\n",
    "#     # Post-process outputs.\n",
    "#     batched_outputs = {\n",
    "#         \"probas\": torch.nn.functional.softmax(out.logits, dim=-1),\n",
    "#         \"input_ids\": encoded_input[\"input_ids\"],\n",
    "#         \"ntok\": torch.sum(encoded_input[\"attention_mask\"], dim=1),\n",
    "#         \"cls_emb\": out.hidden_states[-1][:, 0],  # last layer, first token\n",
    "#     }\n",
    "#     # Return as NumPy for further processing.\n",
    "#     detached_outputs = {k: v.cpu().numpy() for k, v in batched_outputs.items()}\n",
    "#     # Unbatch outputs so we get one record per input example.\n",
    "#     for output in utils.unbatch_preds(detached_outputs):\n",
    "#       ntok = output.pop(\"ntok\")\n",
    "#       output[\"tokens\"] = self.tokenizer.convert_ids_to_tokens(\n",
    "#           output.pop(\"input_ids\")[1:ntok - 1])\n",
    "#       yield output\n",
    "\n",
    "#   def input_spec(self) -> lit_types.Spec:\n",
    "#     return {\n",
    "#         \"sentence\": lit_types.TextSegment(),\n",
    "#         \"label\": lit_types.CategoryLabel(vocab=self.LABELS, required=False)\n",
    "#     }\n",
    "\n",
    "#   def output_spec(self) -> lit_types.Spec:\n",
    "#     return {\n",
    "#         \"tokens\": lit_types.Tokens(),\n",
    "#         \"probas\": lit_types.MulticlassPreds(parent=\"label\", vocab=self.LABELS),\n",
    "#         \"cls_emb\": lit_types.Embeddings()\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.432541Z",
     "start_time": "2022-01-30T06:57:57.426222Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "B64IFx5g461l"
   },
   "outputs": [],
   "source": [
    "# dataset = MultiNLIData(df_train.sample(1800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.437519Z",
     "start_time": "2022-01-30T06:57:57.433466Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "qR0nbr94v2xz"
   },
   "outputs": [],
   "source": [
    "# datasets = {\"sst_dev\": dataset}\n",
    "# models = {\"sst\": SimpleSentimentModel(\"/content/drive/MyDrive/model/best_model/\")}\n",
    "# # models = {\"sst\": SimpleSentimentModel(\"bert-base-uncased\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.442578Z",
     "start_time": "2022-01-30T06:57:57.438383Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "WR8VwsH9v4l8"
   },
   "outputs": [],
   "source": [
    "# from lit_nlp import notebook\n",
    "# widget = notebook.LitWidget(models, datasets, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.447617Z",
     "start_time": "2022-01-30T06:57:57.443466Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "wNPctrXDBQSM"
   },
   "outputs": [],
   "source": [
    "# mm = models[\"sst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.452489Z",
     "start_time": "2022-01-30T06:57:57.448525Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "lHX6hJtVCAuX"
   },
   "outputs": [],
   "source": [
    "# mm.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.457324Z",
     "start_time": "2022-01-30T06:57:57.453292Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "cihtCCxC3ftN"
   },
   "outputs": [],
   "source": [
    "# widget.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T06:57:57.462231Z",
     "start_time": "2022-01-30T06:57:57.458161Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "h5c4S99U5UOS"
   },
   "outputs": [],
   "source": [
    "# dataset.LABELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WxSfPfOF7dNo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UHZ2GHS2YPJx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dZufJ9IYxafN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SUEQvcwK5884"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UlBpR4nZ8Pm4"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KOfzGtQA13Lk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgHgeymrvwfF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vzRGjrB78JEU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hisO325IxQp8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Kbe4pgmh1gQY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pretrained_RoBert_SRL(AVG)_CL(V).ipynb",
   "provenance": [
    {
     "file_id": "1Ia2qfBUM35tzgRmKb8NFZn9V7WQ6xHLQ",
     "timestamp": 1634194650187
    },
    {
     "file_id": "1m63ML-bYzKDT2V9B4hE-Uu5VTx505sa-",
     "timestamp": 1633515541576
    },
    {
     "file_id": "1HhJHiV3RPKbpPFWZrMSHMW_H-OMu45nh",
     "timestamp": 1633492228905
    },
    {
     "file_id": "1q_DO6QMqbQjEru1iCP0CuwA1-0wOBgO1",
     "timestamp": 1633469450109
    },
    {
     "file_id": "1UmCPDjec7zH3RdCY3Hdite8oomF7nmf9",
     "timestamp": 1633290928316
    },
    {
     "file_id": "1w9vwLdm73DBRpQkWEjXqs5q-sfG5CFRP",
     "timestamp": 1633210989154
    },
    {
     "file_id": "1dItOUA_nHj-f307fzTileirMZodw9QQA",
     "timestamp": 1633052138904
    },
    {
     "file_id": "1Oo-71ViOwxENoHeitS3_bKCwW5v34UxN",
     "timestamp": 1632660498277
    },
    {
     "file_id": "1el47BmEzo31ysADRwzhNG8eWTFAGBwSd",
     "timestamp": 1632523116920
    },
    {
     "file_id": "1_JaZBt7ogFAsddWCCG0LcCdgNRAxqtFk",
     "timestamp": 1632443626664
    },
    {
     "file_id": "19E0FxMVVPc7sOJKBKGMO92IFUiH9i8Nq",
     "timestamp": 1631945855961
    },
    {
     "file_id": "1-IQze66iqGbhkSN5Ht7pAfMMsY-XRwDI",
     "timestamp": 1631743166519
    },
    {
     "file_id": "1WejxgDbBCZ7I2Y_ODwi3kgRtrnkLvn-b",
     "timestamp": 1631518058457
    },
    {
     "file_id": "1npRyGEmBJbLWSua7ANgxcMxsQsuWXnKG",
     "timestamp": 1631425160358
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
